{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.spatial import cKDTree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your task is to modify `KNNClassifier` class from your practice in class. The `KNNClassifier` class with empty methods is provided below. Please, modify it to do all tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNNClassifier(object):\n",
    "    \n",
    "    def __init__(self, max_dist=1., use_kd_tree=False, use_weights=False):\n",
    "        \"\"\"\n",
    "        This is a constructor of the class. \n",
    "        Here you can define parameters (max_dist) of the class and \n",
    "        attributes, that are visible within all methods of the class.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        max_dist : float\n",
    "            Maximum distance between an object and its neighbors.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Make this parameter visible in all methods of the class\n",
    "        self.max_dist = max_dist\n",
    "        self.use_kd_tree = use_kd_tree\n",
    "        self.use_weights = use_weights\n",
    "        \n",
    "        self.X_train = None\n",
    "        self.Y_train = None\n",
    "                \n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        This method trains the KNN classifier. \n",
    "        Actualy, the KNN classifier has no training procedure.\n",
    "        It just remembers data (X, y) that will be used for predictions.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : numpy.array, shape = (n_objects, n_features)\n",
    "            Matrix of objects that are described by their input features.\n",
    "        y : numpy.array, shape = (n_objects)\n",
    "            1D array with the object labels. \n",
    "            For the classification labels are integers in {0, 1, 2, ...}.\n",
    "        \"\"\"\n",
    "        \n",
    "        ### Your code here\n",
    "        self.X_train = X\n",
    "        self.Y_train = y\n",
    "        \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        This methods performs labels prediction for new objects.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : numpy.array, shape = (n_objects, n_features)\n",
    "            Matrix of objects that are described by their input features.\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        y_predicted : numpy.array, shape = (n_objects)\n",
    "            1D array with predicted labels. \n",
    "            For the classification labels are integers in {0, 1, 2, ...}.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Create an empty list for predicted labels\n",
    "        y_predicted = []\n",
    "        \n",
    "        ### Replace this line with your code:\n",
    "        for main_x in X:\n",
    "            if self.use_kd_tree:\n",
    "                kd_tree = cKDTree(data=self.X_train, leafsize=30)\n",
    "                dist_neighbors = kd_tree.query_ball_point(x=main_x, r=self.max_dist)\n",
    "                \n",
    "                if len(dist_neighbors) == 0:\n",
    "                    dist_neighbors = kd_tree.query(main_x, 1)\n",
    "           \n",
    "            else:  \n",
    "                calc_dist = lambda main_x, x : np.sqrt((main_x[0] - x[0]) ** 2 + (main_x[1] - x[1]) ** 2)\n",
    "                dists = np.array([calc_dist(main_x, one_x) for one_x in self.X_train])\n",
    "                \n",
    "                neighbors_values = dists[dists <= self.max_dist]\n",
    "                neighbors_indexes = np.argsort(dists)\n",
    "                dist_neighbors = neighbors_indexes[:len(neighbors_values)]\n",
    "                \n",
    "                if len(dist_neighbors) == 0:\n",
    "                    dist_neighbors = neighbors_indexes[0]\n",
    "                \n",
    "            neighbors_labels = self.Y_train[dist_neighbors]\n",
    "            \n",
    "            if self.use_weights:\n",
    "                calc_weights = lambda main_x, x : 1.0 / np.sqrt((main_x[0] - x[0]) ** 2 + (main_x[1] - x[1]) ** 2)\n",
    "                weights = np.array([calc_weights(main_x, one_x) for one_x in self.X_train])\n",
    "                \n",
    "                first_class, second_class = [], []\n",
    "                for node in dist_neighbors:\n",
    "                    if self.Y_train[node] == 0:\n",
    "                        first_class.append(node)\n",
    "                    elif self.Y_train[node] == 1:\n",
    "                        second_class.append(node)\n",
    "                    \n",
    "                first_weights, second_weights = 0, 0\n",
    "                for index in first_class:\n",
    "                    first_weights += weights[index]\n",
    "                \n",
    "                for index in second_class:\n",
    "                    second_weights += weights[index]\n",
    "                    \n",
    "                if first_weights < second_weights:\n",
    "                    y_predicted.append(1)\n",
    "                else:\n",
    "                    y_predicted.append(0)\n",
    "                \n",
    "            else:\n",
    "                unique_labels, label_counts = np.unique(neighbors_labels, return_counts=True)\n",
    "                label_max_count = unique_labels[label_counts == label_counts.max()][0]\n",
    "                y_predicted.append(label_max_count)\n",
    "        \n",
    "        ### The end of your code\n",
    "            \n",
    "        return np.array(y_predicted) # return numpy.array\n",
    "    \n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"\n",
    "        This methods performs prediction of probabilities of each class for new objects.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : numpy.array, shape = (n_objects, n_features)\n",
    "            Matrix of objects that are described by their input features.\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        y_predicted_proba : numpy.array, shape = (n_objects, n_classes)\n",
    "            2D array with predicted probabilities of each class. \n",
    "            Example:\n",
    "                y_predicted_proba = [[0.1, 0.9],\n",
    "                                     [0.8, 0.2], \n",
    "                                     [0.0, 1.0], \n",
    "                                     ...]\n",
    "        \"\"\"\n",
    "        \n",
    "        # Create an empty list for predictions\n",
    "        y_predicted_proba = []\n",
    "        \n",
    "        ### Replace these lines with your code:\n",
    "        for main_x in X:\n",
    "            kd_tree = cKDTree(data=self.X_train, leafsize=30)\n",
    "            dist_neighbors = kd_tree.query_ball_point(x=main_x, r=self.max_dist)\n",
    "\n",
    "            if len(dist_neighbors) == 0:\n",
    "                dist_neighbors = kd_tree.query(main_x, 1)\n",
    "            \n",
    "            #neighbors_labels = self.Y_train[dist_neighbors]\n",
    "                    \n",
    "            probabilities = [0, 0]\n",
    "            calc_weights = lambda main_x, x : 1.0 / np.sqrt((main_x[0] - x[0]) ** 2 + (main_x[1] - x[1]) ** 2)\n",
    "            weights = np.array([calc_weights(main_x, one_x) for one_x in self.X_train])\n",
    "            \n",
    "            for index in dist_neighbors:\n",
    "                if self.Y_train[index] == 0:\n",
    "                    probabilities[0] += weights[index]\n",
    "                else:\n",
    "                     probabilities[1] += weights[index]\n",
    "            \n",
    "            probabilities /= sum(probabilities)\n",
    "            y_predicted_proba.append(probabilities)\n",
    "        \n",
    "        ### The end of your code\n",
    "            \n",
    "        return np.array(y_predicted_proba) # return numpy.array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1 (1 point) <br/>\n",
    "Create a matrix of object features `X` and vector of labels `y` for N=1000 objects using `sklearn.datasets.make_moons()` function from scikit-learn library. Also, set up random state in the function `random_state=42` and `noise=0.2`. To open the function description use `Shift` + `Tab` ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your code here\n",
    "X, y = make_moons(n_samples=1000, random_state=42, noise=0.2)\n",
    "\n",
    "\n",
    "### Check your solution\n",
    "ans = np.array([[-0.112,  0.52 ],\n",
    "                [ 1.143, -0.343]])\n",
    "assert np.array_equal(np.round(X[:2], 3), ans), ('Check your solution.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2 (1 point) <br/>\n",
    "\n",
    "Split the sample into train and test samples using `sklearn.model_selection.train_test_split()` function from scikit-learn library. Use `random_state = 42` and `test_size = 0.5`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your code here\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42)\n",
    "\n",
    "\n",
    "### Check your solution\n",
    "ans = np.array([[ 0.77 , -0.289],\n",
    "                [ 0.239,  1.041]])\n",
    "assert np.array_equal(np.round(X_train[:2], 3), ans), ('Check your solution.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3 (2 points) <br/>\n",
    "\n",
    "Modify class `KNNClassifier` above and implement `predict()` method that uses **max_dist** parameter to select neighbors like it's shown in the second figure (radius search). If there is no any object within **max_dist**, make decision based on the closest neighbor.\n",
    "\n",
    "<img src=\"img/knn2.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 781 ms, sys: 97 µs, total: 781 ms\n",
      "Wall time: 781 ms\n",
      "Test accuracy of KNN classifier:  0.964\n"
     ]
    }
   ],
   "source": [
    "# Create a class object\n",
    "knn = KNNClassifier(max_dist=0.5)\n",
    "\n",
    "# Train the classifier\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Make prediction using the trained classifier\n",
    "%time y_test_predict = knn.predict(X_test) # measure time for prediction\n",
    "\n",
    "# Import accuracy_score function\n",
    "from sklearn.metrics import accuracy_score\n",
    "# Calculate accuracy for the test sample\n",
    "accuracy_test = accuracy_score(y_test, y_test_predict)\n",
    "print(\"Test accuracy of KNN classifier: \", accuracy_test)\n",
    "\n",
    "\n",
    "### Check your solution\n",
    "assert accuracy_test == 0.964, ('Check your solution.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4 (2 points) <br/>\n",
    "\n",
    "There are an algorithm [kd-tree](https://en.wikipedia.org/wiki/K-d_tree) that helps to find neighbors faster. Using [scipy.spatial.cKDTree](https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.spatial.cKDTree.html#scipy.spatial.cKDTree) function modify you classifier to speed up **predict** method. Use `leafsize=30` in `KDTree`. Similar to `max_dist` option, add option `use_kd_tree = True/False` to your classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 125 ms, sys: 3.81 ms, total: 129 ms\n",
      "Wall time: 128 ms\n",
      "Test accuracy of KNN classifier:  0.964\n"
     ]
    }
   ],
   "source": [
    "# Create a class object\n",
    "knn = KNNClassifier(max_dist=0.5, use_kd_tree=True)\n",
    "\n",
    "# Train the classifier\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Make prediction using the trained classifier\n",
    "%time y_test_predict = knn.predict(X_test) # measure time for prediction\n",
    "\n",
    "# Import accuracy_score function\n",
    "from sklearn.metrics import accuracy_score\n",
    "# Calculate accuracy for the test sample\n",
    "accuracy_test = accuracy_score(y_test, y_test_predict)\n",
    "print(\"Test accuracy of KNN classifier: \", accuracy_test)\n",
    "\n",
    "### Check your solution\n",
    "assert accuracy_test == 0.964, ('Check your solution.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5 (3 points) <br/>\n",
    "\n",
    "Now modify the **predict** method to provide prediction with neighbors weights.\n",
    "\n",
    "<img src=\"img/wv1.png\">\n",
    "\n",
    "<img src=\"img/wv2.png\">\n",
    "\n",
    "We propose you to use the following weights:\n",
    "\n",
    "$$\n",
    "w_{i} = \\frac{1}{\\rho(x, x_{i})}\n",
    "$$\n",
    "\n",
    "Similar to `max_dist` option, add option `use_weights = True/False` to your classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 913 ms, sys: 56 µs, total: 913 ms\n",
      "Wall time: 912 ms\n",
      "Test accuracy of KNN classifier:  0.968\n"
     ]
    }
   ],
   "source": [
    "# Create a class object\n",
    "knn = KNNClassifier(max_dist=0.5, use_kd_tree=True, use_weights=True)\n",
    "\n",
    "# Train the classifier\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Make prediction using the trained classifier\n",
    "%time y_test_predict = knn.predict(X_test) # measure time for prediction\n",
    "\n",
    "# Import accuracy_score function\n",
    "from sklearn.metrics import accuracy_score\n",
    "# Calculate accuracy for the test sample\n",
    "accuracy_test = accuracy_score(y_test, y_test_predict)\n",
    "print(\"Test accuracy of KNN classifier: \", accuracy_test)\n",
    "\n",
    "\n",
    "\n",
    "### Check your solution\n",
    "assert accuracy_test == 0.968, ('Check your solution.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 6 (3 points) <br/>\n",
    "\n",
    "Develop **predict_proba** method of the classifier. For each object this method returns probability that the object belongs to each of the classes. \n",
    "\n",
    "For each object $x$ probability for each class is defined as:\n",
    "\n",
    "$$\n",
    "p_{c}(x) = \\frac{g_{c}(x)}{\\sum_{i=1}^{C} g_{i}(x)}\n",
    "$$\n",
    "\n",
    "where $C$ is number of classes.\n",
    "\n",
    "Then, the object has a vector of probabilities:\n",
    "\n",
    "$$\n",
    "p(x) = (p_{1}(x), p_{2}(x), ..., p_{C}(x))\n",
    "$$\n",
    "\n",
    "Use neighbors weights as in Task 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 910 ms, sys: 3.81 ms, total: 913 ms\n",
      "Wall time: 914 ms\n"
     ]
    }
   ],
   "source": [
    "# Create a class object\n",
    "knn = KNNClassifier(max_dist=0.5, use_kd_tree=True, use_weights=True)\n",
    "\n",
    "# Train the classifier\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Make prediction using the trained classifier\n",
    "%time y_test_predict_proba = knn.predict_proba(X_test) # measure time for prediction\n",
    "\n",
    "# Example of the output\n",
    "y_test_predict_proba[:10, :] # the first 10 rows\n",
    "\n",
    "\n",
    "\n",
    "### Check your solution\n",
    "ans = np.array([[0.046, 0.954],\n",
    "                [0.962, 0.038]])\n",
    "assert np.array_equal(np.round(y_test_predict_proba[:2], 3), ans), ('Check your solution.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
